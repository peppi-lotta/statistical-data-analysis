{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12a1250f-b018-4313-8938-69427f779c32",
   "metadata": {},
   "source": [
    "<h1>Exercise 3</h1>\n",
    "TKO_7093 Statistical Data Analysis / BIMA3015 Statistics in Biomedical Sciences\n",
    "<h2>1.</h2> Apply a multivariable test and obtain P-value for<br>\n",
    "a) 2,3,5,4,4,3&nbsp;&nbsp; 4,2,3,5,2,3&nbsp;&nbsp; 3,1,4,4,3,5<br>\n",
    "b) Fi,Sw,Fi,No,Sw,Fi&nbsp;&nbsp; No,Sw,No,Fi,Fi,Fi&nbsp;&nbsp; Sw,Fi,No,Sw,Sw,No\n",
    "\n",
    "<h2>2.</h2> In this exercise we consider articles\n",
    "<h4>Article 4:</h4> X. Xing et al., Decoding the multicellular ecosystem of lung adenocarcinoma\n",
    "manifested as pulmonary subsolid nodules by single-cell RNA sequencing, PMID: 33571124<br>\n",
    "<h4>Article 5:</h4> L.L. Liang et al., Covid‚Äê19 mortality is negatively associated with test number and\n",
    "government effectiveness, PMID: 32709854<br><br>\n",
    "Identify type of variables and methods used to create<br>\n",
    "a) Article_4 and Figure 3 (J).<br>\n",
    "b) Article_5 and Figure 1.<br>\n",
    "\n",
    "<h2>3.</h2> In this exercise we consider file simulated_data_2_5.csv. It has four groups of 100\n",
    "observation: F, G, H and I. Apply multivariable test and obtain P-value<br>\n",
    "a) to compare columns F, G and H.<br>\n",
    "b) to compare columns F, G and I.<br>\n",
    "\n",
    "<h2>4.</h2>\n",
    "Which multiple correction methods are used (if any) in Articles 1-5?\n",
    "\n",
    "<h2>5.</h2> \n",
    "In this exercise we use `Horse Colic data set` from\n",
    "<a href=\"https://archive.ics.uci.edu/ml/datasets/Horse+Colic\">https://archive.ics.uci.edu/ml/datasets/Horse+Colic</a> (the `horse-colic.data` file under `Data\n",
    "Folder`), which contained in the UCI Machine Learning Repository. <br>Download the data, read\n",
    "it to your software and make sure that the missing values (question marks) are handled\n",
    "correctly.<br>\n",
    "Does the horse colic data provide statistical evidence that the mean `rectal temperature` or\n",
    "`age` or `pulse` are different between colic horses treated without surgery and those treated\n",
    "with surgery?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c6e41e3-9350-4b76-94f2-ab8ee8b85769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import scipy\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import statsmodels\n",
    "from statsmodels import formula\n",
    "from statsmodels import api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f65a065c-896c-4485-a8e7-d1b59abf245d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Pvalue for dataset A according to Shapiro-Wilks test: 0.8200848698616028\n",
      "Pvalue for dataset B according to Shapiro-Wilks test: 0.4206596314907074\n",
      "Pvalue for dataset C according to Shapiro-Wilks test: 0.5543804168701172 \n",
      "\n",
      "              df     sum_sq   mean_sq         F    PR(>F)\n",
      "C(dataset)   2.0   0.333333  0.166667  0.115385  0.891807\n",
      "Residual    15.0  21.666667  1.444444       NaN       NaN \n",
      "\n",
      "   level_0  level_1   0\n",
      "0        1        0  Fi\n",
      "1        1        1  Sw\n",
      "2        1        2  Fi\n",
      "3        1        3  No\n",
      "4        1        4  Sw\n",
      "5        1        5  Fi\n",
      "6        2        0  No\n",
      "7        2        1  Sw\n",
      "8        2        2  No\n",
      "9        2        3  Fi\n",
      "10       2        4  Fi\n",
      "11       2        5  Fi\n",
      "12       3        0  Sw\n",
      "13       3        1  Fi\n",
      "14       3        2  No\n",
      "15       3        3  Sw\n",
      "16       3        4  Sw\n",
      "17       3        5  No\n",
      "level_0  1  2  3\n",
      "0               \n",
      "Fi       3  3  1\n",
      "No       1  2  2\n",
      "Sw       2  1  3\n",
      "p = 0.6369783501089177\n"
     ]
    }
   ],
   "source": [
    "print(\"1\")\n",
    "\n",
    "# Create data\n",
    "data=pd.DataFrame({\"dataset1\":(2,3,5,4,4,3),\"dataset2\":(4,2,3,5,2,3),\"dataset3\":(3,1,4,4,3,5)})\n",
    "modified_data=pd.melt(data,value_vars=['dataset1','dataset2','dataset3'])\n",
    "modified_data.columns=['dataset','value']\n",
    "\n",
    "# Test normality\n",
    "shap1 = stats.shapiro(data['dataset1'])\n",
    "shap2 = stats.shapiro(data['dataset2'])\n",
    "shap3 = stats.shapiro(data['dataset3'])\n",
    "print('Pvalue for dataset A according to Shapiro-Wilks test:', shap1.pvalue)\n",
    "print('Pvalue for dataset B according to Shapiro-Wilks test:', shap2.pvalue)\n",
    "print('Pvalue for dataset C according to Shapiro-Wilks test:', shap3.pvalue, '\\n')\n",
    "# All normally distributed\n",
    "\n",
    "# Model\n",
    "model=statsmodels.formula.api.ols('value~C(dataset)',data=modified_data).fit()\n",
    "\n",
    "# ANOVA\n",
    "anova = statsmodels.api.stats.anova_lm(model,typ=1)\n",
    "print(anova, \"\\n\")\n",
    "\n",
    "#_____________________________________________________________________________________________________________\n",
    "#  Fi,Sw,Fi,No,Sw,Fi   No,Sw,No,Fi,Fi,Fi   Sw,Fi,No,Sw,Sw,No\n",
    "#    dataset1 dataset2 dataset3\n",
    "# Fi    3        3        1\n",
    "# Sw    2        1        3\n",
    "# No    1        2        2  '\n",
    "set1 = pd.Series(['Fi','Sw','Fi','No','Sw','Fi'])\n",
    "set2 = pd.Series(['No','Sw','No','Fi','Fi','Fi'])\n",
    "set3 = pd.Series(['Sw','Fi','No','Sw','Sw','No'])\n",
    "df = pd.concat([set1,set2,set3], keys=['1', '2', '3']).reset_index()\n",
    "print(df)\n",
    "cros = pd.crosstab(index=df[0], columns=df['level_0'])\n",
    "print(cros)\n",
    "chi = scipy.stats.chi2_contingency(cros)\n",
    "print(\"p =\", chi[1])\n",
    "\n",
    "#_____________________________________________________________________________________________________________\n",
    "# df = pd.concat([set1,set2,set3], axis=1)\n",
    "# counts = df.apply(pd.Series.value_counts)\n",
    "# chi = scipy.stats.chi2_contingency(counts)[1]\n",
    "# chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa894ccc-e838-456d-b940-03b0308fa1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "    Unnamed: 0      F      G     H      I\n",
      "0            1  27.42  24.02  0.00   9.96\n",
      "1            2 -11.29  20.90  4.67   5.66\n",
      "2            3   7.26 -20.06  6.34  15.53\n",
      "3            4  12.66  36.97  8.12   6.08\n",
      "4            5   8.09 -13.34  1.25  10.31\n",
      "..         ...    ...    ...   ...    ...\n",
      "95          96 -17.22  21.72  3.05  14.14\n",
      "96          97 -22.63   8.08  3.67  10.70\n",
      "97          98 -29.18  11.73  5.73  18.91\n",
      "98          99   1.60  36.30  4.19  18.24\n",
      "99         100  13.06   2.58  0.75   9.12\n",
      "\n",
      "[100 rows x 5 columns]\n",
      "Pvalue for F dataset according to Shapiro-Wilks test: 0.16530661284923553\n",
      "Pvalue for G dataset according to Shapiro-Wilks test: 0.4589977264404297\n",
      "Pvalue for H dataset according to Shapiro-Wilks test: 0.9414567351341248\n",
      "Pvalue for I dataset according to Shapiro-Wilks test: 0.0012272947933524847 \n",
      "\n",
      "a)\n",
      "               df        sum_sq     mean_sq         F    PR(>F)\n",
      "C(dataset)    2.0   1655.589235  827.794617  3.246674  0.040288\n",
      "Residual    297.0  75725.191665  254.966975       NaN       NaN\n",
      "b)\n",
      "1.1990327166649803e-08\n"
     ]
    }
   ],
   "source": [
    "print(\"3\")\n",
    "loc = r'C:\\Users\\peppi\\Desktop\\lipasto\\statisticalDataAnalysis\\simulated_data_2_5.csv'\n",
    "\n",
    "#import data \n",
    "mydata = pd.read_csv(loc, index_col=False)\n",
    "\n",
    "#DataFrame mydata\n",
    "df = pd.DataFrame(mydata)\n",
    "print(df)\n",
    "\n",
    "shap_F = stats.shapiro(df['F'])\n",
    "print('Pvalue for F dataset according to Shapiro-Wilks test:', shap_F.pvalue)\n",
    "shap_G = stats.shapiro(df['G'])\n",
    "print('Pvalue for G dataset according to Shapiro-Wilks test:', shap_G.pvalue)\n",
    "shap_H = stats.shapiro(df['H'])\n",
    "print('Pvalue for H dataset according to Shapiro-Wilks test:', shap_H.pvalue)\n",
    "shap_I = stats.shapiro(df['I'])\n",
    "print('Pvalue for I dataset according to Shapiro-Wilks test:', shap_I.pvalue, \"\\n\")\n",
    "# normal: f,g,h\n",
    "# not normal: i\n",
    "#_____________________________________________________________________________________________________________\n",
    "print(\"a)\") \n",
    "# to compare columns F, G and H. ANOVA\n",
    "# Create data\n",
    "data=pd.DataFrame({\"F\":df[\"F\"],\"G\":df[\"G\"],\"H\":df[\"H\"]})\n",
    "modified_data=pd.melt(data,value_vars=['F','G','H'])\n",
    "modified_data.columns=['dataset','value']\n",
    "# Model\n",
    "model=statsmodels.formula.api.ols('value~C(dataset)',data=modified_data).fit()\n",
    "# ANOVA\n",
    "anova= statsmodels.api.stats.anova_lm(model,typ=1)\n",
    "print(anova)\n",
    "\n",
    "#_____________________________________________________________________________________________________________\n",
    "print(\"b)\") \n",
    "# to compare columns F, G and I. Kruskal\n",
    "kruskal = scipy.stats.kruskal(df[\"F\"],df[\"G\"],df[\"I\"])[1]\n",
    "print(kruskal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "671879da-d1c1-41f7-8eb5-4af55f8255e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "       0  1     3      4\n",
      "0    2.0  1  38.5   66.0\n",
      "1    1.0  1  39.2   88.0\n",
      "2    2.0  1  38.3   40.0\n",
      "3    1.0  9  39.1  164.0\n",
      "4    2.0  1  37.3  104.0\n",
      "..   ... ..   ...    ...\n",
      "294  2.0  1  38.5   40.0\n",
      "296  2.0  1  37.2   72.0\n",
      "297  1.0  1  37.5   72.0\n",
      "298  1.0  1  36.5  100.0\n",
      "299  1.0  1  37.2   40.0\n",
      "\n",
      "[233 rows x 4 columns]\n",
      "Surgery: \n",
      " 1    1.010769e-21\n",
      "3    3.839641e-03\n",
      "4    5.782765e-07\n",
      "dtype: float64\n",
      "No surgery: \n",
      " 1    2.378648e-20\n",
      "3    2.810015e-02\n",
      "4    7.143510e-09\n",
      "dtype: float64\n",
      "Pvalue from Mann‚ÄìWhitney U test for dataset 3 : 0.46257320393656\n",
      "Pvalue from Mann‚ÄìWhitney U test for dataset 4 : 0.0022994239860838262\n",
      "        level_0  level_1  1     3      4\n",
      "0       surgery        1  1  39.2   88.0\n",
      "1       surgery        3  9  39.1  164.0\n",
      "2       surgery        6  1  37.9   48.0\n",
      "3       surgery       10  1  38.1   66.0\n",
      "4       surgery       12  1  37.2   42.0\n",
      "..          ...      ... ..   ...    ...\n",
      "228  no_surgery      286  1  37.8   82.0\n",
      "229  no_surgery      287  9  39.5   84.0\n",
      "230  no_surgery      290  1  38.6   45.0\n",
      "231  no_surgery      294  1  38.5   40.0\n",
      "232  no_surgery      296  1  37.2   72.0\n",
      "\n",
      "[233 rows x 5 columns]\n",
      "level_0  no_surgery  surgery\n",
      "1                           \n",
      "1                93      120\n",
      "9                 5       15\n",
      "0.16771971654705192\n"
     ]
    }
   ],
   "source": [
    "print(\"5\")\n",
    "loc = r'C:\\Users\\peppi\\Desktop\\lipasto\\statisticalDataAnalysis\\horse-colic.data'\n",
    "\n",
    "#import data \n",
    "mydata = pd.read_csv(loc, sep=\"\\s+\", header=None)\n",
    "\n",
    "#DataFrame mydata\n",
    "df = pd.DataFrame(mydata)\n",
    "\n",
    "#   1:  surgery?,   2:  Age,   4:  rectal temperature,   5:  pulse \n",
    "df = df[[0, 1, 3, 4]]\n",
    "\n",
    "# to numeric if not numeric get NaN value (so ? -> NaN) \n",
    "# then drop rows with NaN values.  \n",
    "df = df.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "print(df)\n",
    "\n",
    "#make surgery and no-surgery data sets\n",
    "surgery = df.loc[df[0] == 1][[1,3,4]]\n",
    "no_surgery = df.loc[df[0] == 2][[1,3,4]]\n",
    "\n",
    "# test normality of all columns\n",
    "print(\"Surgery:\",\"\\n\",surgery.apply(lambda a: stats.shapiro(a).pvalue))\n",
    "print(\"No surgery:\",\"\\n\",no_surgery[[1,3,4]].apply(lambda a: stats.shapiro(a).pvalue))\n",
    "# None of the columns are normal\n",
    "\n",
    "# We need to use  Mann-Whitney\n",
    "mwu = stats.mannwhitneyu(surgery[3],no_surgery[3],use_continuity=True,alternative='two-sided').pvalue\n",
    "print(\"Pvalue from Mann‚ÄìWhitney U test for dataset\", 3, \":\", mwu)\n",
    "mwu = stats.mannwhitneyu(surgery[4],no_surgery[4],use_continuity=True,alternative='two-sided').pvalue\n",
    "print(\"Pvalue from Mann‚ÄìWhitney U test for dataset\", 4, \":\", mwu)\n",
    "\n",
    "#for age (1) -> chi\n",
    "df = pd.concat([surgery,no_surgery], keys=['surgery', 'no_surgery']).reset_index()\n",
    "print(df)\n",
    "cros = pd.crosstab(index=df[1], columns=df['level_0'])\n",
    "print(cros)\n",
    "chi = scipy.stats.chi2_contingency(cros)   \n",
    "print(chi[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fc2d23-6ac4-4d4d-a8d9-6c545b0e370e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
